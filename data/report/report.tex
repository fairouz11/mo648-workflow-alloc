\documentclass[a4paper,10pt]{article}

% escreve textos gerados em portugues
\usepackage[brazilian]{babel}
% aceita unicode
\usepackage[utf8]{inputenc}
% pacotes para inserção de imagens
\usepackage{graphicx}
\usepackage{epstopdf}
\DeclareGraphicsExtensions{.pdf,.png,.eps}
% pacote para fórmulas matemáticas
\usepackage{amsmath}


\title{Comparação de algoritmos de escalonamento de workflows para redes híbridas}
\author{Aloisio Vilas-Boas\and Andre Petris Esteve\and Atilio Gomes Luiz}
\date{\today}

%% \pdfinfo{%
%%   /Title    ()
%%   /Author   ()
%%   /Creator  ()
%%   /Producer ()
%%   /Subject  ()
%%   /Keywords ()
%% }

\begin{document}

\maketitle

\begin{center}
--------------------------------------------------------------------------------------------\\
Universidade Estadual de Campinas\\
Instituto de Computação\\
MO648 - Projeto de Redes Multimídia\\
Prof. Dr. Nelson Luis Saldanha da Fonseca\\
--------------------------------------------------------------------------------------------\\
\end{center}

\section{Introdução}

Workflows científicos têm sido utilizados atualmente para representar uma grande variedade de aplicações envolvendo
alto processamento e grandes capacidades de armazenamento. Alguns domínios do conhecimento tais como a biologia estrutural,
física quântica e neuro-ciência envolvem experimentos científicos cuja análise dos dados torna-se possível apenas por meio de sua representação
na forma de workflows científicos\cite{pso_a}.\\

Um workflow pode ser descrito como um Grafo Acíclico e Direcionado \emph{(DAG, do inglês, Directed Acyclic Graph)} no qual cada tarefa 
é representada por um nó e cada fluxo de dados entre tarefas é representado por uma aresta direcionada entre os nós correspondentes. O escalonamento 
de workflows consiste em mapear cada tarefa de um workflow para um recurso(processador) apropriado, tal que o cálculo total do mapeamento produzido 
satisfaça algum critério de performance (custo, tempo, etc). Como esse problema é bem conhecido ser um problema NP-Completo, muitas heurísticas têm 
sido propostas \cite{bit}, \cite{pso_a}, \cite{pcp}.

Dessa forma, técnicas de gerenciamento de workflows fazem-se necessárias, principalmente em ambientes distribuídos 
envolvendo serviços providos por nuvens.\\

A computação em nuvem é um novo paradigma para computação distribuída onde três tipos principais de serviços são fornecidos. São eles\footnote{http://pt.wikipedia.org/wiki/Computacao em nuvem}:

\begin{enumerate}

    \item IaaS - Infrastructure as a Service ou Infraestrutura como Serviço: quando se utiliza uma porcentagem de um servidor, geralmente com configuração que se adeque à sua necessidade.

    \item PaaS - Plataform as a Service ou Plataforma como Serviço: utilizando-se apenas uma plataforma como um banco de dados, um web-service, etc.

    \item SaaS - Software as a Service ou Software como Serviço: uso de um software em regime de utilização web.

\end{enumerate}


Em termos de disponibilidade de recursos, nós podemos classificar nuvens de Infraestrutura como Serviço(IaaS clouds) em três 
tipos diferentes \cite{hcoc}:

\begin{enumerate}

  \item Nuvens públicas: os provedores de recursos oferecem recursos de computação (processamento, armazenamento, etc) como serviços e os usuários 
  pagam por tempo de serviço utilizado. 
  
  \item Nuvens privadas: nuvens com recursos que podem ser acessados e usados por indivíduos dentro de uma organização. Nuvens privadas são 
  similares a grids privadas.

  \item Nuvens híbridas: São um misto de nuvens públicas e privadas.

\end{enumerate}

A computação por demanda oferecida pelas nuvens públicas pode ser utilizada como um recurso auxiliar para o uso de nuvens privadas (computadores, clusters e grids), 
tal que, a medida que as aplicações do cliente necessitem de recursos adicionais, esses 
recursos sejam disponibilizados pelas nuvens públicas. Contudo, a abordagem híbrida resulta em sistemas com novas demandas em gerenciamento 
de recursos. A medida que as aplicações devem lidar com nuvens públicas e privadas, um esforço adicional deve ser feito para decidir quanto 
de recurso adicional deve ser utilizado. Desta forma, todas as vezes que uma aplicação do cliente necessita de serviços adicionais 
que não podem ser fornecidos pela rede privada, a aplicação subscreve o seu pedido para para uma nuvem pública. 
Essa nuvem pública, por sua vez, fornece o serviço requerido à aplicação.\\


Um escalonador de workflows deve levar em consideração o contexto acima para tentar escalonar as tarefas do workflow de modo 
eficiente e a um custo reduzido dentro de redes híbridos. Os escalonadores de workflows podem ter diferentes políticas que 
variam de acordo com a função objetivo: minimizar o tempo de execução total, minimizar o custo total, balancear a quantidade de recursos 
usados ao mesmo tempo que as alcança as restrições de deadline da aplicação, e assim por diante.

No presente trabalho, nós focamos no estudo e na implementação de quatro algoritmos para escalonamento de workflows em nuvens híbridas. 
Dois desses algoritmos (Algoritmo aleatório e Algoritmo round robin) são, de fato, bem simples e serviram para uma comparação em relação a outros dois 
algoritmos mais sofisticados (Partial Critical Paths e Particle Swarm Optimization). Esses algoritmos foram implementados na linguagem Java utilizando como base para 
a sua implementação um simulador de nuvens chamado \emph{Cloudsim}\cite{cloudsim}.

As tarefas principais desenvolvidas neste trabalho foram:

\begin{itemize}

\item Estudo e aprendizado do funcionamento do simulador \emph{Cloudsim} para modelagem e simulação em computação em nuvens de 
algoritmos de escalonamento de workflows.

\item Estudo e implementação de dois algoritmos de escalonamento de workflows para redes híbridas: \emph{Partial Critical Paths e
Particle Swarm Optimization}. Assim como a implementação de dois algoritmos mais simples, a saber, o algoritmo aleatório e o 
algoritmo round robin.

\item Simulação dos algoritmos e posterior comparação dos resultados. Geração de gráficos e produção de relatório.

\end{itemize}


O restante deste relatório está organizado do seguinte modo: Na seção 2 apresentamos a motivação do trabalho. Na seção 3, o contexto 
do trabalho é descrito. Na seção 4, o objetivo do trabalho é apresentado. Na seção 5, descrevemos os algoritmos que foram implementados. 
Na seção 6, descrevemos o simulador. Na seção 7, descrevemos a metodologia utilizada na realização do projeto. E na seção 8, apresentamos as conclusões.


\section{Motivação}

Podemos listar como motivações para o desenvolvimento deste trabalho:\\

\begin{itemize}

\item Rever os conhecimentos de simulação vistos na disciplina e colocá-los em prática para a resolução de um projeto real.

\item Estudar heurísticas de escalonamento de workflows e fazer sua implementação utilizando um simulador de nuvens.

\item O objetivo de produzir um ótimo trabalho visando não somente um resultado satisfatório, mas também uma excelente 
avaliação ao final da realização deste projeto.

\item (mais coisas?....)

\end{itemize}

\section{Descrição do contexto}

Um usuário deseja executar um workflow de tarefas representado por um \emph{grafo acíclico 
direcionado} (DAG). Cada tarefa é representada por um nó no DAG. Se uma tarefa depende de
resultados de outra tarefa, então há um arco ligando os nós das respectivas tarefas no DAG.
Um nó possui um peso relacionado ao número de intruções necessárias para que a tarefa seja executada.
Já um arco possui um peso relacionado ao tamanho dos dados que devem ser transferidos entre tarefas
dependentes.

O usuário tem disponível uma infraestrutura de nuvem híbrida para execução do 
seu workflow. Essa infra-estrutura é composta por diferentes nuvens: (a) uma nuvem 
privada, onde execuções de tarefas não acarretam custos monetários ao usuário; e (b) 
nuvens públicas nas quais o usuário paga pelo tempo de processamento utilizado.

Este usuário tem um requisito de qualidade de serviço relacionado 
ao tempo de execução do seu workflow, que chamamos de deadline. Dessa forma, o tempo 
de execução do workflow deve ser menor que o deadline.

O objetivo do usuário é realizar o escalonamento de seu DAG nos recursos da 
nuvem híbridas dentro do deadline estipulado minimizando o custo monetário.

\section{Objetivo do projeto}

Este projeto teve como objetivo comparar diferentes algorítmos de escalonamento 
para redes híbidas. Foram implementados quatro algoritmos: \emph{escalonador aleatório}, \emph{round robin},
\emph{cost-driven scheduling using partial critial paths} e \emph{algoritmo de otimização por nuvem de partículas}.
Os algoritmos são descritos na próxima seção.

\section{Descrição dos Algorítmos}
\label{algoritmos}

\subsection{Algoritmo Aleatório}

O algorítmo baseia-se na alocação aleatória de recursos para o processamento de tarefas do workflow.

Este escalonador realiza os seguintes passos:

\begin{enumerate}

    \item Realize a ordenação topológica do grafo de workflows.

    \item Enquanto o grafo for não vazio, escolha um nó sem dependentes, ou seja, uma tarefa que não possua dependências 
(ou cujas dependências já foram executadas).

    \item Aleatoriamente selecione um recurso da nuvem e atribua a execução da tarefa selecionada ao recurso.

    \item Remova o nó (tarefa) do grafo (workflow) e volte ao item 2 caso haja ainda tarefas a serem alocadas.

\end{enumerate}

O escalonador aleatório foi implementado apenas para servir como um limitante inferior para a análise.
Não esperamos que nenhum dos demais escalonadores tenha uma performance inferior ao deste algoritmo.

\subsection{Algoritmo Round Robin}

O algoritmo baseia-se na alocação seqüêncial de recursos para o processamento de tarefas do workflow.

Este escalonador realiza os seguintes passos:

\begin{enumerate}

    \item Realize a ordenação topológica do grafo de workflows.

    \item A cada recurso da nuvem atribua um identificador único entre 0 e N-1, onde N é o número de recursos.

    \item Defina o contador 'i' como 0.

    \item Enquanto o grafo for não vazio, escolha um nó sem dependentes, ou seja, uma tarefa que não possua dependências 
(ou cujas dependências já foram executadas).

    \item Selecione o recurso da nuvem cujo identificador é (i mod N).

    \item Atribua a execução da tarefa selecionada ao recurso obtido no item 5.

    \item Incremente o contador 'i'.

    \item Remova o nó (tarefa) do grafo (workflow) e volte ao item 4 caso haja ainda tarefas a serem alocadas.

\end{enumerate}

Este escalonador serve como base para as comparações. Espera-se que os demais algoritmos (com exceção do escalonador
aleatório) apresentem melhor performance.

\subsection{Cost-driven Scheduling Using Partial Critical Paths}

(Descrever algorítmo)

\subsection{Algorítmo de Otimização por Nuvem de Partículas}

A solução para o problema de escalonamento, apresentada no artigo \cite{pso_a}, é baseada numa heurística 
denominada \emph{Particle Swarm Optimization} (PSO) ou \emph{Otimização por Nuvem de Partículas}. A heurística de 
escalonamento tem como objetivo otimizar 
o custo do mapeamento tarefa-máquina baseada na solução dada pelo PSO. O processo de otimização utiliza 
dois algoritmos principais: (a) A heurística de escalonamento desenvolvida pelos autores e (b) Os passos do PSO 
para otimização do mapeamento tarefa-máquina. Antes de apresentar os algoritmos, vamos 
dar uma breve descrição do algoritmo PSO.

\subsubsection{Particle Swarm Optimization - PSO}

Particle Swarm Optimization(PSO) ou Otimização por Nuvem de Partículas é um algorítmo originalmente 
desenvolvido por Eberhart e Kennedy \cite{pso_article}. O PSO é inspirado na simulação do comportamento social de um 
bando de pássaros em revoada, com movimento localmente aleatório, mas globalmente determinado. No PSO, 
assim como em outros algorítmos, existe uma população de indivíduos, chamados de nuvem (ou enxame) de 
partículas, que em vez de utilizar operadores genéticos, evoluem através de cooperação e competição, entre si, 
por diversas gerações. As partículas se beneficiam de sua própria experiência e da experiência de outros membros 
do enxame durante a busca de um melhor fitness (alvo: comida, local para repouso, proteção de predadores, etc).

\subsubsection{Estrutura do PSO}

O PSO é muito similar a algumas técnicas da computação evolucionária, como os algoritmos genéticos, onde o 
sistema é inicializado com uma população de soluções aleatórias. Entretanto, difere dessas outras técnicas 
populacionais, pois nenhum operador inspirado pelos procedimentos de DNA, é aplicado na população, para obter 
uma nova geração de indivíduos. Em vez de mutação, são utilizadas partículas, movendo-se em um espaço de busca 
n-dimensional, sendo cada uma delas um solução potencial para o problema. Cada partícula possui também uma 
velocidade que é inicializada aleatoriamente, para que possa percorrer o espaço de soluções do problema.

A $i$-ésima partícula é representada por:
\begin{equation}
X_{i} = (X_{i1}, X_{i2},\ldots, X_{id})
\end{equation}
A melhor solução prévia, ou seja, a posição que dá o melhor valor de aptidão da $i$-ésima partícula, é registrada e representada por:
\begin{equation}
P_{i} = (P_{i1}, P_{i2},\ldots, P_{id})
\end{equation}
A taxa da mudança de posição, que é chamada de velocidade, para a partícula $i$, é representada por:
\begin{equation}
V_{i} = (V_{i1}, V_{i2},\ldots, V_{id})
\end{equation}
As partículas são manipuladas pelas seguintes equações:
\begin{equation}
v_{i}^{k+1} = w*v_{i}^k + c_{1}*rand_{1} * (pbest_{i} - x_{i}^k) + c_{2}*rand_{2} * (gbest - x_{i}^k) \label{velocidade}
\end{equation}
\begin{equation}
x_{i}^{k+1} = x_{i}^k + v_{i}^{k+1} \label{posicao}
\end{equation}

Onde:\\

\begin{description}
\item
$v_{i}^k$ - velocidade da partícula $i$ na $k$-ésima iteração\\
$v_{i}^{k+1}$ - velocidade da partícula $i$ na $(k+1)$-ésima iteração\\
$w$ – fator de inércia que determina a diversificação ou a intensificação das partículas\\
$c_{j}$ – coeficientes de aceleração; $j$ = 1,2\\
$rand_{i}$ – números randômicos entre 0 e 1; $i$ = 1,2\\
$x_{i}^k$ – posição atual da partícula $i$ na $k$-ésima iteração\\
$pbest_{i}$ – melhor posição da partícula $i$\\
$gbest$ – posição da melhor partícula da população\\
$x_{i}^{k+1}$ – posição da partícula $i$ na $(k+1)$-ésima iteração\\
\end{description}

A Equação \eqref{velocidade} é usada para calcular a nova velocidade da partícula, de acordo com sua velocidade 
anterior e as distâncias entre sua posição atual, sua melhor posição, e a melhor posição do grupo. 
A partir daí a partícula muda para uma nova posição de acordo com a Equação \eqref{posicao}. O desempenho de cada 
partícula é medido de acordo com uma função de aptidão pré-definida que é relacionada ao problema a ser 
resolvido. No nosso problema, essa função de aptidão tenta minimizar os custos das alocações dos recursos 
recursos feitas em cada partícula. No PSO, cada partícula representa uma possível solução para o problema.
Cada uma dessas soluções é refinada através de n iterações; sendo escolhida, ao final, a melhor solução de todas,
ou seja, a solução (\emph{fitness}) que possui o menor custo total.\\

Cada partícula mantém o rastro de suas coordenadas no espaço-problema, que estão associadas à 
melhor solução (\emph{fitness}) que ela tenha encontrado até então. O valor do fitness também é armazenado. 
Esse valor é chamado de \emph{pbest}. Outro valor que é rastreado é o melhor entre todos os valores, e sua posição, 
obtido por qualquer partícula na população. Esse valor é chamado de \emph{gbest}.\\

O conceito do PSO consiste a cada iteração, em mudança de velocidade, as partículas 
alcancem suas posições de \emph{pbest} e \emph{gbest}. O algoritmo PSO, tal como descrito pelos 
autores do artigo, pode ser visto nos passos abaixo:\\

\begin{description}
\item[1:] Set particle dimension as equal to the size of ready tasks.
\item[2:] Initialize particles position and velocity randomly.
\item[3:] For each particle, calculate its fitness value.
\item[4:] If the fitness value is better than the previous best \emph{pbest}, set the current fitness value as the new \emph{pbest}.
\item[5:] After Steps 3 and 4 for all particles, select the best particle as \emph{gbest}.
\item[6:] For all particles, calculate velocity using Equation \eqref{posicao} and update their positions using Equation \eqref{velocidade}.
\item[7:] If the stopping criteria or maximum iteration is not satisfied, repeat from Step 3.
\end{description}



\subsubsection{Explicação do PSO}

O algoritmo começa com a inicialização aleatória da posição e velocidade das partículas. Neste projeto, 
cada partícula representa um mapeamento tarefa-máquina, onde cada tarefa \emph{i} ($0 \leq i < \text{número de tarefas}$) representa uma dimensão da partícula
e cada dimensão recebe valores inteiros, onde cada um desses valores representa o ID da máquina para qual a tarefa $i$ deve ser atribuída.\\

Deste modo, uma partícula \emph{p} representa um mapeamento de uma tarefa para uma máquina. No nosso problema, por exemplo, se o 
algoritmo receber como entrada um workflow com 5 tarefas, cada partícula, na primeira chamada do PSO, terá 5 dimensões, que poderão variar 
a medida que o algoritmo é executado. O conteúdo de cada dimensão $i$ da partícula, ($0 \leq i < \text{número de tarefas}$), 
é o identificador(ID) da máquina para a qual a tarefa $i$ deve ser atribuída. Por exemplo, uma partícula inicial no nosso algoritmo, 
pode ser melhor ilustrada na Figura \eqref{particula}.\\

\begin{figure}[!htb]
\centering
\includegraphics[scale=.5]{figures/fig1.eps}
\caption{Exemplo de partícula para um workflow com 5 tarefas}
\label{particula}
\end{figure}

\subsubsection{Explicação da heurística de escalonamento}

A heurística de escalonamento apresentada pelos autores do artigo, utiliza como recurso principal o PSO e pode ser resumida nos passos
apresentados logo abaixo:\\

\begin{description}
\item[1:] Calculate average computation cost of all tasks in all compute resources.
\item[2:] Calculate average cost of (communication/size of data) between resources.
\item[3:] Compute PSO(\emph{allTasks}) /* where \emph{allTasks} is a set of all tasks of the workflow */
\item[4:] repeat steps 5 to 10 until there are unscheduled tasks
\item[5:] for all ''ready'' tasks do: assign tasks $t_{i}$ to resources $p_{j}$ according to the solution provided by PSO
\item[6:] Dispatch all the mapped tasks
\item[7:] Wait for \emph{polling time}
\item[8:] Update the ready task list
\item[9:] Update the average cost of communication between resources according to the current network load
\item[10:] Compute PSO(remainingTasks)
\end{description}

Os valores para custo médio de computação e comunicação, assim como os valores para o tamanho 
do arquivo transmitido entre tarefas, são computados de acordo com os dados passados como entrada para o simulador.\\

O passo inicial do algorítmo é computar o mapeamento de todas as tarefas do workflow, independente das dependências
existentes entre as tarefas(passo 3: Compute PSO((allTasks)). Este mapeamento otimiza o custo total de computação do workflow. 
Para validar as dependências entre as tarefas, o algoritmo atribui as tarefas prontas para os hosts de acordo com o 
mapeamento dado pelo PSO (passo 5). Após despachar as tarefas para execução, o escalonador espera um determinado tempo, que
os autores do artigo denominaram \emph{polling time}. Esse tempo é para o simulador adquirir o status das tarefas.
Na nossa simulação, ao invés de esperar um determinado tempo, o escalonador atribui as tarefas aos hosts e continua a sua execução, sendo
avisado a qualquer momento pelo simulador(cloudsim) do término de uma tarefa. Todas as vezes que o escalonador é avisado do término de tarefas, 
o algoritmo PSO é chamado para que a geração de um novo mapeamento tarefa-máquina seja gerado (passo 7). Desta forma, o algoritmo PSO tal como
implementado pode ser denominado um algoritmo online.\\

Dependendo da quantidade de tarefas finalizadas, a lista de tarefas prontas é atualizada, essa lista conterá todas as tarefas 
cujos pais completaram sua execução e já transmitiram todos os arquivos necessários (passo 8). No passo 9, os autores 
atualizam a matriz com os valores dos custos de comunicação entre os recursos pois, segundo o modelo implementado por eles, 
esses valores podem variar. No caso da nossa implementação, esses valores são fixos, logo esse passo não precisou ser implementado 
no nosso projeto. No passo 10, o PSO é computado novamente para as tarefas que ainda não foram escalonadas. Os passos 6 a 10 
são repetidos até que todas as tarefas do worflow estejam escalonadas.\\

A Tabela abaixo mostra os valores utilizados na execução do algorítmo de escalonamento PSO. O número de execuções representa o número de 
simulações independentes realizadas para cada workflow dado com entrada para o algorítmo para se calcular o Intervalo de Confiança dos resultados.\\

\begin{figure}[!htb]
\centering
\includegraphics[scale=.4]{figures/valuesPSO.eps}
\caption{Valores utilizados no algoritmo PSO}
\label{psoValues}
\end{figure}

\section{O simulador}

Para realizar a comparação dos algorítmos, foi necessário utilizar um simulador de nuvens. O simulador é
responsável por receber e tratar os pedidos de alocação de tarefas, bem como os pedidos de transmissão dos
resultados de uma tarefa executada.

Foi implementado um simulador que atendesse aos requisitos descritos anteriormente. A implementação baseou-se
em um, já consolidado, simulador de nuvens chamado \emph{cloudsim}\cite{cloudsim}.

As alterações feitas e decisões de projeto tomadas são descritas com detalhes abaixo.

\subsection{Arquitetura}

A fim de que fosse possível testar um número variado de algorítmos e que a implementação do escalonador
não estivesse altamente acoplada ao funcionamento do simulador, decidimos adicionar uma camada de abstração
ao projeto.

Essa camada de abstração provê funcionalidades básicas ao implementador do escalonador, sem revelar como o
simulador as implementa. Desta forma, é possível alterar o simulador subjacente sem alterar o código dos escalonadores,
bem como é possível desenvolver um escalonador sem conhecer qual será o simulador utilizado.

Do ponto de vista da implementação, a camada de abstração é um conjunto de interfaces que define os contratos
entre os escalonadores e o simulador.
Ela é genérica o suficiente para permitir que diferentes escalonadores sejam suportados por diferentes simuladores.

O principal motivo dessa decisão de projeto foi permitir o desenvolvimento em paralelo da implementação dos escalonadores
e do simulador.

Portanto, a arquitetura do projeto é como vista abaixo.

\begin{center}
----------------------------------------------------------\\
                ESCALONADORES                 \\
----------------------------------------------------------\\
             CAMADA DE ABSTRAÇÃO              \\
----------------------------------------------------------\\
        SIMULADOR (CLOUDSIM MODIFICADO)        \\
----------------------------------------------------------\\
\end{center}

\subsection{Interface do escalonador}

O escalonador deve implementar uma interface que permite as seguintes
interações entre ele e o simulador:

\begin{enumerate}

  \item Inicialização
  \item Evento: fim de execução de tarefa previamente alocada
  \item Evento: fim de transmissão de dados

\end{enumerate}

Abaixo descrevemos cada possível interação entre o simulador e o escalonador.

Em (1) o escalonador deve preparar o ambiente para iniciar as alocações. Se o escalonador
não se importar com os eventos do simulador, ele pode realizar a alocação de todas as tarefas
neste momento. Nota: ao menos uma tarefa deve ser alocada nesta etapa, pois caso nenhuma tarefa
seja alocada o simulador termina, uma vez que não há o que simular.

Em (2) o simulador avisa ao escalonador que uma tarefa previamente alocada terminou sua execução.
O escalonador pode obter informações sobre o processamento, bem como alocar novas tarefas, se desejar.

Em (3) o simulador avisa ao escalonador que uma transmissão de dados terminou.
O escalonador pode obter informações sobre a transmissão, bem como alocar novas tarefas, se desejar.

\subsection{Interface do simulador}

O simulador deve, por sua vez, implementar uma interface que permite que escalonadores
realizem operações básicas durante a simulação. Essas operações são:

\begin{enumerate}

  \item Obter tarefas (DAG do workflow)
  \item Obter recursos (recursos da rede pública e privada)
  \item Alocar uma tarefa
  \item Alocar uma transmissão

\end{enumerate}

Abaixo descrevemos cada funcionalidade:

Em (1) o simulador provê o DAG que contém as tarefas, suas dependências e os pesos das tarefas (número
de instruções) e os pesos dos arcos (tamanho dos dados a serem transmitidos entre tarefas dependentes).

Em (2) o simulador provê uma lista de recursos da nuvem hibrida. Os recursos da nuvem privada diferem
dos da nuvem publica por não possuirem custo atrelado a sua utilização.

Em (3) o simulador permite que o escalonador aloque uma tarefa para execução em um recurso da nuvem.

Em (4) o simulador permite que o escalonador aloque uma transmissão de dados (resultado de uma tarefa)
entre recursos da rede. A limitação imposta aqui é que uma transmissão só é válida se ela iniciar em um
recurso que executou a tarefa cujos dados estão sendo transmitidos.

\subsection{Alterações do simulador}

Nesta seção descrevemos quais foram os requisitos que não estavam presentes no simulador original
e que foram implementados na nossa versão.

Utilizamos o \emph{cloudsim}\footnote{http://www.cloudbus.org/cloudsim/} release 2.1.1 como base para as modificações.
 
O simulador de nuvens \emph{cloudsim} não serviu imediatamente ao nosso propósito. Algumas funcionalidades
não eram implementadas ou eram parcialmente implementadas:

\begin{enumerate}

  \item Simulação da transmissão de resultados entre recursos
  \item Simular fila de transmissões
  \item Considerar dependências de tarefas antes de iniciar sua execução

\end{enumerate}

Abaixo exemplificamos cada requisito.

Considere duas tarefas A e B, sendo que B depende dos resultados de A para executar.
Considere também dois recursos $\alpha$ e $\beta$.
Se A for alocada em $\alpha$ e B em $\beta$, então antes de B iniciar em $\beta$ é necessário
que sejam transmitidos os dados gerados por A de $\alpha$ para $\beta$.

Realizar a simulação da transmissão e considerar o tempo gasto durante o processo é o
requisito descrito em (1).

Tendo em mente o exemplo anterior, suponha que foi alocada uma terceira tarefa, C, em
$\alpha$, antes que A fosse alocada. Contudo, o escalonador já previu a transmissão do
resultado de A para $\beta$. Assim é necessário manter uma fila de transmissões entre
recursos. Desta forma, é possível simular um canal entre dois recursos e garantir que
o canal realize uma transmissão por vez, bem como enfileirar transmissões requisitadas
em um canal em uso. Este é o requisito (2).

O requisito (3) é necessário uma vez que uma tarefa não pode ser executada até que todas
suas dependências tenham sido transmitidas ao recurso que realizará a execução. Desta forma,
caso uma tarefa seja alocada e suas dependências ainda não tenham terminado de ser transmitidas
a tarefa consome processamento do recurso, mas não avança sua execução.

\section{Metodologia}

O experimento proposto deseja verificar a performance dos algoritmos de escalonamento
descritos na seção \ref{algoritmos}. Para isso foi estipulado um cenário padrão, que
compreende a configuração dos recursos nos quais as tarefas serão executadas.

O cenário foi definido como na tabela \ref{tab:datacenter}.

\begin{table}
\centering

  \begin{tabular}{|l|l|}  

%    Datacenter & Processamento (kMIPS) & C \\ \hline
%    a & b &c \\ \hline

  \end{tabular}
  \caption{Configuração de recursos usada no experimento}
  \label{tab:datacenter}
\end{table}

O experimento consiste da execução de diversos DAGs (vide seção \ref{grafosusados}),
cada grafo representando um workflow.


\subsection{Grafos usados}
\label{grafosusados}

(Descrever grafos usados)

\begin{figure}[!htb]

\centering
\includegraphics[scale=.25]{figures/airsn.png}
\caption{AIRSN \protect\cite{bit}}
\label{airsn}

\centering
\includegraphics[scale=.25]{figures/chimera1.png}
\caption{Chimera 1 \protect\cite{bit}}
\label{chimera1}

\centering
\includegraphics[scale=.25]{figures/chimera2.png}
\caption{Chimera 2 \protect\cite{bit}}
\label{chimera2}

\centering
\includegraphics[scale=.25]{figures/ligo.png}
\caption{LIGO \protect\cite{bit}}
\label{ligo}

\centering
\includegraphics[scale=.25]{figures/montage.png}
\caption{Montage \protect\cite{bit}}
\label{montage}

\end{figure}

\subsection{Experimentos realizados}

(Descrever os experimentos - tipos de coisas q vamos plotar e analisar)

\subsection{Resultados}

(Resultados, gráficos...)

\section{Conclusão}

(Conclusões)

\section{Agradecimentos}

Agradecimentos

\begin{thebibliography}{9}

\bibitem{bit}
  Luiz F. Bittencourt, Rizos Sakellariou and Edmundo R. M. Madeira,
  \emph{DAG Scheduling Using a Lookahead Variant
of the Heterogeneous Earliest Finish Time Algorithm}.
  2010 18th Euromicro Conference on Parallel Distributed and Networkbased Processing.

\bibitem{cloudsim}
  Rodrigo N. Calheiros, Rajiv Ranjan, Anton Beloglazov, Cesar A. F. De Rose, and Rajkumar Buyya
  \emph{CloudSim: A Toolkit for Modeling and Simulation of Cloud Computing Environments and Evaluation of Resource Provisioning Algorithms}.
  Software: Practice and Experience (SPE),
  Volume 41, Number 1, Pages: 23-50, ISSN: 0038-0644,
  Wiley Press, New York, USA, January, 2011.

\bibitem{pso_a}
  Suraj Pandey, Linlin Wu, Siddeswara M. Guru, Rajkumar Buyya.
  \emph{A particle swarm    optimization-based heuristic for scheduling workflow applications in cloud computing environments}. 
  In: 24th IEEE INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS. Melbourn, Australia. 2010.               

\bibitem{pcp}
  Saeid Abrishami, Mahmoud Naghibzadeh, Dick Epema. 
  \emph{Cost-driven scheduling of grid workflows using partial critical paths}. 
  In: 11th IEEE/ACM INTERNATIONAL CONFERENCE ON GRID COMPUTING. October, 2010.
                                                    

\bibitem{pso_article}
   James Kennedy, Russel Eberhart. 
   \emph{Particle swarm optimization}. 
   In: IEEE International Conference on Neural Networks. 1995.

\bibitem{hcoc}
   Luiz Fernando Bittencourt, Edmundo Roberto Mauro Madeira.
   \emph{HCOC: a cost optimization algorithm for workflow scheduling in hybrid clouds}. 2010.
 

\end{thebibliography}

\end{document}
